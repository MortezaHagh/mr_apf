{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 201,
   "id": "4a77d2a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Multi-Robot APF Results Analysis\n",
    "# This notebook analyzes the performance results from different test configurations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "id": "446ab868",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "# import seaborn as sns\n",
    "from typing import Dict, List, Any\n",
    "\n",
    "# Set up plotting style\n",
    "plt.style.use('default')\n",
    "# sns.set_palette(\"husl\")\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.width', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "id": "f90189b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_all_results(base_dir: str = '.') -> pd.DataFrame:\n",
    "    results = []\n",
    "    base_path = Path(base_dir)\n",
    "\n",
    "    # Find all res.json files in subdirectories\n",
    "    for json_file in base_path.rglob('res.json'):\n",
    "        try:\n",
    "            with open(json_file, 'r') as f:\n",
    "                data = json.load(f)\n",
    "\n",
    "            # Add folder name for reference\n",
    "            data['folder_name'] = json_file.parent.name\n",
    "            results.append(data)\n",
    "            # print(f\"Loaded: {json_file}\")\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error loading {json_file}: {e}\")\n",
    "\n",
    "    if not results:\n",
    "        print(\"No res.json files found!\")\n",
    "        return pd.DataFrame()\n",
    "\n",
    "    df = pd.DataFrame(results)\n",
    "\n",
    "    # #\n",
    "    # print(f\"\\nLoaded {len(df)} result files\")\n",
    "    # print(f\"Columns: {list(df.columns)}\")\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "id": "3bd6065a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def refine_dataframe(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    # Drop rows with nD == 3D\n",
    "    df = df[df['nD'] != '3D']\n",
    "\n",
    "    # Only keep relevant columns\n",
    "    relevant_columns = ['map_id', 'n_robots', 'method', 'success', 'operation_time', 'total_length', 'max_steps']\n",
    "    df = df[relevant_columns]\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "id": "c334a45c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# group by map_id and create tables for each map\n",
    "def map_tables(df: pd.DataFrame) -> Dict[str, pd.DataFrame]:\n",
    "    tables = {}\n",
    "    for map_id, map_data in df.groupby('map_id'):\n",
    "        tables[map_id] = map_data\n",
    "    return tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "id": "46f3b861",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_performance_tables(tables: Dict[str, pd.DataFrame], metric: str) -> Dict[int, pd.DataFrame]:\n",
    "    #  create table from df (which is for a specific map), columns are n_robots, index are methods, values are metric\n",
    "    p_tables = {}\n",
    "    for i, df in tables.items():\n",
    "        table = df.pivot_table(index='method', columns='n_robots', values=metric, aggfunc=np.mean)\n",
    "        p_tables[i] = table\n",
    "    return p_tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "id": "f6b4d3bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load all results\n",
    "df_all = load_all_results('./static_tests')\n",
    "df_all = refine_dataframe(df_all)\n",
    "df_all.head(100)\n",
    "\n",
    "# if success is False, set operation_time and total_length and max_steps to NaN\n",
    "df_all.loc[~df_all['success'], ['operation_time', 'total_length', 'max_steps']] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "id": "5a65613b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Performance Table for Map ID: 1\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>n_robots</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>method</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1433.0</td>\n",
       "      <td>1435.0</td>\n",
       "      <td>1441.0</td>\n",
       "      <td>1468.0</td>\n",
       "      <td>1446.0</td>\n",
       "      <td>1487.0</td>\n",
       "      <td>1624.0</td>\n",
       "      <td>1512.0</td>\n",
       "      <td>2601.0</td>\n",
       "      <td>1584.0</td>\n",
       "      <td>1682.0</td>\n",
       "      <td>1718.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>835.0</td>\n",
       "      <td>843.0</td>\n",
       "      <td>877.0</td>\n",
       "      <td>845.0</td>\n",
       "      <td>947.0</td>\n",
       "      <td>968.0</td>\n",
       "      <td>927.0</td>\n",
       "      <td>928.0</td>\n",
       "      <td>991.0</td>\n",
       "      <td>1288.0</td>\n",
       "      <td>1684.0</td>\n",
       "      <td>1108.0</td>\n",
       "      <td>1280.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>835.0</td>\n",
       "      <td>843.0</td>\n",
       "      <td>877.0</td>\n",
       "      <td>845.0</td>\n",
       "      <td>947.0</td>\n",
       "      <td>968.0</td>\n",
       "      <td>927.0</td>\n",
       "      <td>928.0</td>\n",
       "      <td>991.0</td>\n",
       "      <td>1288.0</td>\n",
       "      <td>1684.0</td>\n",
       "      <td>1108.0</td>\n",
       "      <td>1280.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>835.0</td>\n",
       "      <td>848.0</td>\n",
       "      <td>1115.0</td>\n",
       "      <td>993.0</td>\n",
       "      <td>889.0</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>1238.0</td>\n",
       "      <td>1063.0</td>\n",
       "      <td>1175.0</td>\n",
       "      <td>1229.0</td>\n",
       "      <td>1442.0</td>\n",
       "      <td>1362.0</td>\n",
       "      <td>1351.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>835.0</td>\n",
       "      <td>877.0</td>\n",
       "      <td>962.0</td>\n",
       "      <td>1071.0</td>\n",
       "      <td>1244.0</td>\n",
       "      <td>1177.0</td>\n",
       "      <td>1413.0</td>\n",
       "      <td>987.0</td>\n",
       "      <td>970.0</td>\n",
       "      <td>1119.0</td>\n",
       "      <td>1346.0</td>\n",
       "      <td>1161.0</td>\n",
       "      <td>1286.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "n_robots      2       3       4       5       6       7       8       9   \\\n",
       "method                                                                     \n",
       "1         1433.0  1435.0  1441.0  1468.0  1446.0  1487.0  1624.0  1512.0   \n",
       "2          835.0   843.0   877.0   845.0   947.0   968.0   927.0   928.0   \n",
       "3          835.0   843.0   877.0   845.0   947.0   968.0   927.0   928.0   \n",
       "4          835.0   848.0  1115.0   993.0   889.0  1001.0  1238.0  1063.0   \n",
       "5          835.0   877.0   962.0  1071.0  1244.0  1177.0  1413.0   987.0   \n",
       "\n",
       "n_robots      10      11      12      13      14  \n",
       "method                                            \n",
       "1         2601.0  1584.0  1682.0  1718.0     NaN  \n",
       "2          991.0  1288.0  1684.0  1108.0  1280.0  \n",
       "3          991.0  1288.0  1684.0  1108.0  1280.0  \n",
       "4         1175.0  1229.0  1442.0  1362.0  1351.0  \n",
       "5          970.0  1119.0  1346.0  1161.0  1286.0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#\n",
    "tables = map_tables(df_all)\n",
    "tables = create_performance_tables(tables, metric='max_steps')\n",
    "for map_id, table in tables.items():\n",
    "    print(f\"\\nPerformance Table for Map ID: {map_id}\")\n",
    "    display(table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "id": "4a39473a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def analyze_method_performance(df: pd.DataFrame):\n",
    "#     \"\"\"\n",
    "#     Detailed analysis of method performance\n",
    "#     \"\"\"\n",
    "#     print(\"=== METHOD PERFORMANCE ANALYSIS ===\\n\")\n",
    "\n",
    "#     for map_id in sorted(df['map_id'].unique()):\n",
    "#         map_data = df[df['map_id'] == map_id]\n",
    "#         print(f\"MAP {map_id} Analysis:\")\n",
    "#         print(\"-\" * 30)\n",
    "\n",
    "#         # Best method for each metric and robot count\n",
    "#         metrics = ['operation_time', 'total_length']\n",
    "\n",
    "#         for n_robots in sorted(map_data['n_robots'].unique()):\n",
    "#             robot_data = map_data[map_data['n_robots'] == n_robots]\n",
    "#             print(f\"\\n  {n_robots} Robots:\")\n",
    "\n",
    "#             for metric in metrics:\n",
    "#                 if metric in robot_data.columns:\n",
    "#                     best_method = robot_data.loc[robot_data[metric].idxmin(), 'method']\n",
    "#                     best_value = robot_data[metric].min()\n",
    "#                     worst_value = robot_data[metric].max()\n",
    "#                     improvement = ((worst_value - best_value) / worst_value * 100)\n",
    "\n",
    "#                     print(f\"    {metric}: Method {best_method} (Best: {best_value:.2f}, \"\n",
    "#                           f\"Improvement: {improvement:.1f}%)\")\n",
    "\n",
    "#         print(\"\\n\" + \"=\"*50 + \"\\n\")\n",
    "\n",
    "\n",
    "# # Analyze method performance\n",
    "# analyze_method_performance(df_all)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
